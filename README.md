# ETHONLINE2023

AI companies employ ethical hackers to identify risks, for example seeing if AI can be mislead  into making harmful suggestions like endorsing theft. Currently, these evaluations occur in isolated, centralized and closed door environments. This approach might overlook potential vulnerabilities and could inadvertently introduce bias. No wonder The White House has been clear: AI must be continuously tested by groups of people with different backgrounds.   But if you want to help test, you have to give them your personal details. But with so many stories about lost or leaked data, can we really trust them?


Enter "AI Samurai", a decentralized AI safety platform,  it uses ZK credential to protect users privacy, and allow everyone to make AI  more inclusive and safer AI, and getting rewards.<img width="1476" alt="Screenshot 2023-10-22 at 2 20 39 AM" src="https://github.com/dingchaoz/ETHONLINE2023/assets/10751336/12dfed96-0ab7-459f-947c-9ab1cc968ba7">
  <img width="1440" alt="Screenshot 2023-10-22 at 2 22 18 AM" src="https://github.com/dingchaoz/ETHONLINE2023/assets/10751336/8cc19e43-b347-4039-832a-b83d0be6d168">
<img width="1255" alt="Screenshot 2023-10-22 at 2 22 35 AM" src="https://github.com/dingchaoz/ETHONLINE2023/assets/10751336/ba0258d2-7114-43ac-ac12-19782e0e1c6f">
<img width="1387" alt="Screenshot 2023-10-22 at 2 23 02 AM" src="https://github.com/dingchaoz/ETHONLINE2023/assets/10751336/f4fdea0b-2a0a-483b-aeb7-2e1383ed871c">
